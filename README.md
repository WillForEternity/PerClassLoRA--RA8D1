# Temporal Hand Gesture Recognition for Renesas RA8D1

# Temporal Hand Gesture Recognition for Renesas RA8D1

[![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)](https://github.com/WillForEternity/PerClassLoRA--RA8D1)
[![Platform](https://img.shields.io/badge/Platform-Renesas%20RA8D1-blue)](https://www.renesas.com/us/en/products/microcontrollers-microprocessors/ra-cortex-m-mcus/ra8d1-480-mhz-arm-cortex-m85-based-microcontroller-helium-and-trustzone)
[![Memory](https://img.shields.io/badge/Memory-%3C1MB%20SRAM-orange)]()
[![Accuracy](https://img.shields.io/badge/Accuracy-98%25%2B-success)]()

## 1. Project Overview

This project delivers a production-ready, real-time temporal hand gesture recognition system optimized for the Renesas RA8D1 microcontroller. It features a custom-built Temporal Convolutional Network (TCN) designed to operate within a strict 1MB SRAM memory constraint, demonstrating the successful deployment of advanced machine learning on a resource-constrained embedded platform.

The system is fully functional, having resolved critical data pipeline discrepancies between training and inference environments to achieve high accuracy and stable performance in real-world conditions.

## 2. Getting Started

### Prerequisites
- A C compiler (e.g., `gcc` or `clang`)
- `make`
- **Python 3.11** (This specific version is required for GUI dependencies on macOS).

### Automated Execution

The entire application is managed by a single master script. This command builds the C code, sets up the Python environment, starts the C server, and launches the GUI in the correct order.

```bash
# Clone the repository and run the application
git clone https://github.com/WillForEternity/PerClassLoRA--RA8D1.git
cd PerClassLoRA--RA8D1
./start_app.sh
```

The script handles all dependencies and ensures the C server is running before launching the GUI. It also gracefully shuts down all processes on exit.

### Manual Execution (Advanced)
For developers who prefer manual control, the C backend can be compiled and run using the provided `Makefile`.

```bash
# Navigate to the C backend directory
cd RA8D1_Simulation

# Build both the training and inference executables
make all

# To run the executables (after building)
./train_c        # Run the training process
./ra8d1_sim      # Run the inference server

# To clean all build artifacts
make clean
```

## 3. Workflow

1.  **ğŸš€ Initial Setup**: Run `./start_app.sh` to automatically build all components and launch the GUI.
2.  **ğŸ“Š Data Collection**: Use the **Data Collection** tab to record temporal gestures using the live camera feed. Each gesture is captured as a 20-frame sequence and saved as a CSV file in `models/data/{gesture_name}/`.
3.  **ğŸ‹ï¸ Model Training**: Navigate to the **Training** tab and click "Start Training." This invokes the `train_c` executable, which loads the CSV data, runs the training process for 200 epochs, and saves the final `c_model.bin`.
4.  **ğŸ¯ Real-time Inference**: Open the **Inference** tab to see live gesture recognition. The GUI sends normalized hand landmark data to the `ra8d1_sim` server and displays the returned prediction and confidence score.

## 4. System Architecture & Technical Specifications

The system employs a hybrid architecture, leveraging a Python-based GUI for user interaction and a high-performance C backend for model execution.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      Persistent TCP     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Python Frontend â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚    C Backend      â”‚
â”‚ (PyQt6 GUI)       â”‚         Socket          â”‚ (Inference Engine)â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Data Collection â”‚                         â”‚ - TCN Forward Passâ”‚
â”‚ - Training Controlâ”‚                         â”‚ - Model Loading   â”‚
â”‚ - Live Inference  â”‚                         â”‚ - Diagnostics     â”‚
â”‚ - MediaPipe       â”‚                         â”‚ - Static Memory   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                             â–²
         â–¼                                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       C Training        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Training Data    â”‚        Process          â”‚   Binary Model    â”‚
â”‚   (CSV Files)     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º |  (c_model.bin)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

| Component | Technology | Role |
| :--- | :--- | :--- |
| **GUI Frontend** | Python (PyQt6) | Manages user workflow, data collection, and visualization. |
| **Backend Engine** | C | Handles all ML computation (training and inference) with static memory. |
| **Communication** | TCP Sockets | Persistent connection for low-latency binary data streaming. |

### Model & Data Pipeline

| Aspect | Specification |
| :--- | :--- |
| **Model Type** | Custom Temporal Convolutional Network (TCN) with 2 channels. |
| **Input Shape** | 20 frames Ã— 60 features (20 landmarks Ã— 3 coordinates, wrist excluded). |
| **Activation** | Leaky ReLU (Î±=0.01) to prevent dying neurons. |
| **Optimizer** | Adam with He Initialization. |
| **Temporal Sampling**| Stride-5 for both training and inference to ensure consistency. |
| **Memory Footprint** | < 1MB SRAM (Static allocation, verified at compile-time). |
| **Performance** | >98% accuracy; >30 FPS inference speed. |

## 5. Project Structure

```
.
â”œâ”€â”€ README.md                    # This comprehensive documentation
â”œâ”€â”€ start_app.sh                 # Master startup script with process management
â”‚
â”œâ”€â”€ RA8D1_Simulation/            # C Backend Implementation
â”‚   â”œâ”€â”€ main.c                   # TCP inference server main executable
â”‚   â”œâ”€â”€ train_in_c.c             # Training executable main with hyperparameters
â”‚   â”œâ”€â”€ training_logic.c/h       # Core TCN implementation & data structures
â”‚   â”œâ”€â”€ mcu_constraints.h        # RA8D1 memory constraints and compile-time checks
â”‚   â””â”€â”€ Makefile                 # Build system for C executables
â”‚
â”œâ”€â”€ gui_app/                     # Python GUI Application
â”‚   â”œâ”€â”€ main_app.py              # Main PyQt6 application with 4-page navigation
â”‚   â”œâ”€â”€ logic.py                 # Core classes: HandTracker, GesturePredictor
â”‚   â””â”€â”€ ... pages ...            # Individual GUI pages for each workflow stage
â”‚
â”œâ”€â”€ models/                      # Data and Model Storage
â”‚   â”œâ”€â”€ data/                    # Training data organized by gesture class
â”‚   â””â”€â”€ c_model.bin              # Trained TCN model in binary format
â”‚
â””â”€â”€ docs/                        # Project Documentation
    â”œâ”€â”€ explanation.md           # Detailed technical explanation
    â””â”€â”€ struggles.md             # Development challenges and solutions
```

